{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced DVC Pipeline for Insurance Risk Analytics\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a comprehensive DVC implementation with:\n",
    "- Advanced pipeline monitoring and validation\n",
    "- Real-time metrics tracking\n",
    "- Automated error handling and recovery\n",
    "- Data quality validation\n",
    "- Performance optimization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced imports and configuration\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import logging\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Configure logging\n",
    "log_dir = Path('../logs')\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../logs/dvc_pipeline.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../logs', exist_ok=True)\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "os.makedirs('../results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVCPipelineManager:\n",
    "    \"\"\"Enhanced DVC Pipeline Management Class\"\"\"\n",
    "    \n",
    "    def __init__(self, project_root: str = '../'):\n",
    "        self.project_root = Path(project_root)\n",
    "        self.dvc_yaml_path = self.project_root / 'dvc.yaml'\n",
    "        self.params_path = self.project_root / 'params.yaml'\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "    def run_command(self, command: str, timeout: int = 300) -> Tuple[str, str, int]:\n",
    "        \"\"\"Execute shell command with enhanced error handling\"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"Executing: {command}\")\n",
    "            result = subprocess.run(\n",
    "                command, \n",
    "                shell=True, \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                timeout=timeout,\n",
    "                cwd=self.project_root\n",
    "            )\n",
    "            return result.stdout, result.stderr, result.returncode\n",
    "        except subprocess.TimeoutExpired:\n",
    "            self.logger.error(f\"Command timed out: {command}\")\n",
    "            return '', f'Command timed out after {timeout}s', 1\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error executing command: {e}\")\n",
    "            return '', str(e), 1\n",
    "    \n",
    "    def validate_environment(self) -> Dict[str, bool]:\n",
    "        \"\"\"Comprehensive environment validation\"\"\"\n",
    "        checks = {}\n",
    "        \n",
    "        # Check DVC installation\n",
    "        stdout, stderr, code = self.run_command('dvc version')\n",
    "        checks['dvc_installed'] = code == 0\n",
    "        \n",
    "        # Check Git repository\n",
    "        checks['git_repo'] = (self.project_root / '.git').exists()\n",
    "        \n",
    "        # Check DVC initialization\n",
    "        checks['dvc_initialized'] = (self.project_root / '.dvc').exists()\n",
    "        \n",
    "        # Check configuration files\n",
    "        checks['dvc_yaml_exists'] = self.dvc_yaml_path.exists()\n",
    "        checks['params_yaml_exists'] = self.params_path.exists()\n",
    "        \n",
    "        # Check required directories\n",
    "        required_dirs = ['data', 'src', 'outputs', 'results']\n",
    "        for dir_name in required_dirs:\n",
    "            checks[f'{dir_name}_dir_exists'] = (self.project_root / dir_name).exists()\n",
    "        \n",
    "        return checks\n",
    "    \n",
    "    def get_pipeline_status(self) -> Dict[str, any]:\n",
    "        \"\"\"Get comprehensive pipeline status\"\"\"\n",
    "        status = {}\n",
    "        \n",
    "        # DVC status\n",
    "        stdout, stderr, code = self.run_command('dvc status')\n",
    "        status['pipeline_up_to_date'] = code == 0 and not stdout.strip()\n",
    "        status['dvc_status_output'] = stdout if stdout else 'Up to date'\n",
    "        \n",
    "        # Pipeline stages\n",
    "        if self.dvc_yaml_path.exists():\n",
    "            with open(self.dvc_yaml_path, 'r') as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            status['stages'] = list(config.get('stages', {}).keys())\n",
    "            status['total_stages'] = len(status['stages'])\n",
    "        else:\n",
    "            status['stages'] = []\n",
    "            status['total_stages'] = 0\n",
    "        \n",
    "        # Check outputs\n",
    "        status['outputs_exist'] = self._check_outputs_exist()\n",
    "        \n",
    "        return status\n",
    "    \n",
    "    def _check_outputs_exist(self) -> Dict[str, bool]:\n",
    "        \"\"\"Check if expected outputs exist\"\"\"\n",
    "        expected_outputs = {\n",
    "            'processed_data': 'outputs/insurance_data_processed.csv',\n",
    "            'feature_data': 'outputs/insurance_data_features.csv',\n",
    "            'hypothesis_results': 'results/hypothesis_testing/',\n",
    "            'model_results': 'results/models/',\n",
    "            'recommendations': 'results/recommendations.md'\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            name: (self.project_root / path).exists() \n",
    "            for name, path in expected_outputs.items()\n",
    "        }\n",
    "    \n",
    "    def execute_pipeline(self, stage: Optional[str] = None, force: bool = False) -> bool:\n",
    "        \"\"\"Execute pipeline with monitoring\"\"\"\n",
    "        command = 'dvc repro'\n",
    "        if stage:\n",
    "            command += f' {stage}'\n",
    "        if force:\n",
    "            command += ' --force'\n",
    "        \n",
    "        self.logger.info(f\"Starting pipeline execution: {command}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        stdout, stderr, code = self.run_command(command, timeout=1800)  # 30 min timeout\n",
    "        \n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        if code == 0:\n",
    "            self.logger.info(f\"Pipeline completed successfully in {execution_time:.2f}s\")\n",
    "            return True\n",
    "        else:\n",
    "            self.logger.error(f\"Pipeline failed: {stderr}\")\n",
    "            return False\n",
    "    \n",
    "    def generate_metrics_report(self) -> Dict[str, any]:\n",
    "        \"\"\"Generate comprehensive metrics report\"\"\"\n",
    "        report = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'pipeline_health': self.get_pipeline_health_score(),\n",
    "            'model_metrics': self._load_model_metrics(),\n",
    "            'data_quality': self._load_data_quality_metrics(),\n",
    "            'business_impact': self._load_business_metrics()\n",
    "        }\n",
    "        \n",
    "        # Save report\n",
    "        report_path = self.project_root / 'results' / 'pipeline_report.json'\n",
    "        with open(report_path, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def get_pipeline_health_score(self) -> float:\n",
    "        \"\"\"Calculate overall pipeline health score\"\"\"\n",
    "        checks = self.validate_environment()\n",
    "        status = self.get_pipeline_status()\n",
    "        \n",
    "        total_checks = len(checks) + len(status['outputs_exist'])\n",
    "        passed_checks = sum(checks.values()) + sum(status['outputs_exist'].values())\n",
    "        \n",
    "        return (passed_checks / total_checks) * 100\n",
    "    \n",
    "    def _load_model_metrics(self) -> Dict[str, any]:\n",
    "        \"\"\"Load model performance metrics\"\"\"\n",
    "        metrics_path = self.project_root / 'results' / 'models' / 'model_metrics.json'\n",
    "        if metrics_path.exists():\n",
    "            with open(metrics_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _load_data_quality_metrics(self) -> Dict[str, any]:\n",
    "        \"\"\"Load data quality metrics\"\"\"\n",
    "        metrics_path = self.project_root / 'outputs' / 'data_quality_metrics.json'\n",
    "        if metrics_path.exists():\n",
    "            with open(metrics_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _load_business_metrics(self) -> Dict[str, any]:\n",
    "        \"\"\"Load business impact metrics\"\"\"\n",
    "        metrics_path = self.project_root / 'results' / 'business_impact_metrics.json'\n",
    "        if metrics_path.exists():\n",
    "            with open(metrics_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "\n",
    "# Initialize pipeline manager\n",
    "pipeline_manager = DVCPipelineManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 00:29:29,399 - INFO - Executing: dvc version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENHANCED DVC PIPELINE DASHBOARD\n",
      "============================================================\n",
      "\n",
      "ENVIRONMENT VALIDATION\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 00:29:31,509 - INFO - Executing: dvc status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PASS] Dvc Installed: True\n",
      "[PASS] Git Repo: True\n",
      "[PASS] Dvc Initialized: True\n",
      "[PASS] Dvc Yaml Exists: True\n",
      "[PASS] Params Yaml Exists: True\n",
      "[PASS] Data Dir Exists: True\n",
      "[PASS] Src Dir Exists: True\n",
      "[PASS] Outputs Dir Exists: True\n",
      "[PASS] Results Dir Exists: True\n",
      "\n",
      "PIPELINE STATUS\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 00:29:35,435 - INFO - Executing: dvc version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Stages: 5\n",
      "Pipeline Status: Data and pipelines are up to date.\n",
      "\n",
      "\n",
      "OUTPUT VALIDATION\n",
      "------------------------------\n",
      "[EXISTS] Processed Data: True\n",
      "[EXISTS] Feature Data: True\n",
      "[EXISTS] Hypothesis Results: True\n",
      "[EXISTS] Model Results: True\n",
      "[EXISTS] Recommendations: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 00:29:38,123 - INFO - Executing: dvc status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OVERALL HEALTH SCORE: 100.0%\n",
      "STATUS: Excellent! Pipeline is in perfect condition\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Dashboard\n",
    "def create_pipeline_dashboard():\n",
    "    \"\"\"Create comprehensive pipeline dashboard\"\"\"\n",
    "    print('ENHANCED DVC PIPELINE DASHBOARD')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Environment validation\n",
    "    print('\\nENVIRONMENT VALIDATION')\n",
    "    print('-' * 30)\n",
    "    checks = pipeline_manager.validate_environment()\n",
    "    for check, status in checks.items():\n",
    "        status_text = '[PASS]' if status else '[FAIL]'\n",
    "        print(f'{status_text} {check.replace(\"_\", \" \").title()}: {status}')\n",
    "    \n",
    "    # Pipeline status\n",
    "    print('\\nPIPELINE STATUS')\n",
    "    print('-' * 30)\n",
    "    status = pipeline_manager.get_pipeline_status()\n",
    "    print(f'Total Stages: {status[\"total_stages\"]}')\n",
    "    print(f'Pipeline Status: {status[\"dvc_status_output\"]}')\n",
    "    \n",
    "    # Output validation\n",
    "    print('\\nOUTPUT VALIDATION')\n",
    "    print('-' * 30)\n",
    "    for output, exists in status['outputs_exist'].items():\n",
    "        status_text = '[EXISTS]' if exists else '[MISSING]'\n",
    "        print(f'{status_text} {output.replace(\"_\", \" \").title()}: {exists}')\n",
    "    \n",
    "    # Health score\n",
    "    health_score = pipeline_manager.get_pipeline_health_score()\n",
    "    print(f'\\nOVERALL HEALTH SCORE: {health_score:.1f}%')\n",
    "    \n",
    "    if health_score >= 90:\n",
    "        print('STATUS: Excellent! Pipeline is in perfect condition')\n",
    "    elif health_score >= 75:\n",
    "        print('STATUS: Good! Pipeline is working well with minor issues')\n",
    "    elif health_score >= 50:\n",
    "        print('STATUS: Warning! Pipeline needs attention')\n",
    "    else:\n",
    "        print('STATUS: Critical! Pipeline requires immediate fixes')\n",
    "\n",
    "# Execute dashboard\n",
    "create_pipeline_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Pipeline Execution with Monitoring\n",
    "def execute_pipeline_with_monitoring():\n",
    "    \"\"\"Execute pipeline with comprehensive monitoring\"\"\"\n",
    "    print('ADVANCED PIPELINE EXECUTION')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Pre-execution validation\n",
    "    print('\\nPRE-EXECUTION VALIDATION')\n",
    "    checks = pipeline_manager.validate_environment()\n",
    "    critical_checks = ['dvc_installed', 'dvc_initialized', 'dvc_yaml_exists']\n",
    "    \n",
    "    for check in critical_checks:\n",
    "        if not checks.get(check, False):\n",
    "            print(f'[FAIL] Critical check failed: {check}')\n",
    "            return False\n",
    "    \n",
    "    print('[PASS] All critical checks passed')\n",
    "    \n",
    "    # Execute pipeline\n",
    "    print('\\nEXECUTING PIPELINE')\n",
    "    success = pipeline_manager.execute_pipeline()\n",
    "    \n",
    "    if success:\n",
    "        print('[SUCCESS] Pipeline executed successfully')\n",
    "        \n",
    "        # Generate metrics report\n",
    "        print('\\nGENERATING METRICS REPORT')\n",
    "        report = pipeline_manager.generate_metrics_report()\n",
    "        print(f'Report saved with timestamp: {report[\"timestamp\"]}')\n",
    "        print(f'Final health score: {report[\"pipeline_health\"]:.1f}%')\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print('[ERROR] Pipeline execution failed')\n",
    "        return False\n",
    "\n",
    "# Execute with monitoring (uncomment to run)\n",
    "# execute_pipeline_with_monitoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Visualization Dashboard\n",
    "def create_metrics_visualization():\n",
    "    \"\"\"Create comprehensive metrics visualization\"\"\"\n",
    "    print('METRICS VISUALIZATION DASHBOARD')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Load metrics\n",
    "    model_metrics = pipeline_manager._load_model_metrics()\n",
    "    \n",
    "    if not model_metrics:\n",
    "        print('[WARNING] No model metrics available yet')\n",
    "        return\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Model Performance Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Model comparison\n",
    "    models = list(model_metrics.keys())\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i//2, i%2]\n",
    "        values = [model_metrics[model].get(metric, 0) for model in models]\n",
    "        \n",
    "        bars = ax.bar(models, values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "        ax.set_title(f'{metric.upper()} Comparison', fontweight='bold')\n",
    "        ax.set_ylabel(metric.capitalize())\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/metrics_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print('\\nMODEL PERFORMANCE SUMMARY')\n",
    "    print('-' * 40)\n",
    "    for model, metrics in model_metrics.items():\n",
    "        print(f'\\n{model.upper()}:')\n",
    "        for metric, value in metrics.items():\n",
    "            print(f'  {metric}: {value:.3f}')\n",
    "\n",
    "# Create visualization (uncomment to run)\n",
    "# create_metrics_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "### Enhanced Features Implemented\n",
    "\n",
    "1. **Advanced Pipeline Management Class**\n",
    "   - Comprehensive error handling\n",
    "   - Environment validation\n",
    "   - Real-time monitoring\n",
    "   - Automated reporting\n",
    "\n",
    "2. **Enhanced Configuration**\n",
    "   - Structured parameters file\n",
    "   - Comprehensive metrics tracking\n",
    "   - Multiple model support\n",
    "   - Advanced plotting configuration\n",
    "\n",
    "3. **Monitoring and Visualization**\n",
    "   - Real-time dashboard\n",
    "   - Health score calculation\n",
    "   - Metrics visualization\n",
    "   - Automated report generation\n",
    "\n",
    "### Usage Instructions\n",
    "\n",
    "1. **Initialize Pipeline**: Run the dashboard to check environment\n",
    "2. **Execute Pipeline**: Use the advanced monitoring function\n",
    "3. **View Results**: Check the metrics visualization\n",
    "4. **Monitor Health**: Regular health score monitoring\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
